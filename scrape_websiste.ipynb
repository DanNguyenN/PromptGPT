{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def scrape_prompts(integer):\n",
    "    url = f\"https://library.easyprompt.xyz/prompt/{integer}\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    prompts = soup.find_all(\"div\", class_=\"prompt\")\n",
    "\n",
    "    for prompt in prompts:\n",
    "        print(prompt.get_text())\n",
    "\n",
    "# Specify the integer value for the URL\n",
    "integer_value = 123\n",
    "\n",
    "# Call the scrape_prompts function\n",
    "scrape_prompts(integer_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f\"https://library.easyprompt.xyz/prompt/123\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "#prompt_content = soup.find('div', class_='prompt-content').get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Craft a LinkedIn Headline that effectively communicates your professional identity and personal brand to your network and potential employers. Your headline should be concise and attention-grabbing, and should convey your key skills, experiences, and career goals. Consider using industry-specific keywords that are relevant to your field and that potential employers may search for. Your headline should also showcase your unique value proposition and differentiate you from other professionals in your field. Additionally, consider including any relevant certifications, degrees, or awards that are pertinent to your professional identity. Finally, ensure that your headline aligns with your overall LinkedIn profile and accurately reflects your current professional status.\n",
      "\n",
      "Example Context: You are a freelance graphic designer with over five years of experience in the industry. You specialize in branding and identity design for small businesses and startups. Your goal is to attract potential clients and showcase your expertise in your field. Your LinkedIn Headline should be written in a way that appeals to business owners and entrepreneurs looking for high-quality branding services.\n",
      "LinkedIn Headline\n"
     ]
    }
   ],
   "source": [
    "print(soup.find('div', class_=\"utils_response__b5jEi\").get_text())\n",
    "print(soup.find('p', class_=\"text-xl font-display\").get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">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\n",
       "</pre>\n"
      ],
      "text/plain": [
       "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\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "\n",
    "HF_KEY = os.getenv(\"HF_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/null/.cache/huggingface/datasets/csv/default-3022fbe3053ce4fa/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "970920b04c264f788eb525b32c58ce96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">DatasetDict</span><span style=\"font-weight: bold\">({</span>\n",
       "    train: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dataset</span><span style=\"font-weight: bold\">({</span>\n",
       "        features: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'base_prompt'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'improved_prompt'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'views'</span><span style=\"font-weight: bold\">]</span>,\n",
       "        num_rows: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">341</span>\n",
       "    <span style=\"font-weight: bold\">})</span>\n",
       "<span style=\"font-weight: bold\">})</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mDatasetDict\u001b[0m\u001b[1m(\u001b[0m\u001b[1m{\u001b[0m\n",
       "    train: \u001b[1;35mDataset\u001b[0m\u001b[1m(\u001b[0m\u001b[1m{\u001b[0m\n",
       "        features: \u001b[1m[\u001b[0m\u001b[32m'base_prompt'\u001b[0m, \u001b[32m'improved_prompt'\u001b[0m, \u001b[32m'views'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        num_rows: \u001b[1;36m341\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Original column name train not in the dataset. Current columns in the dataset: ['base_prompt', 'improved_prompt', 'views']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/null/code/PromptGPT/scrape_websiste.ipynb Cell 4\u001b[0m in \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/null/code/PromptGPT/scrape_websiste.ipynb#W3sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(dataset)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/null/code/PromptGPT/scrape_websiste.ipynb#W3sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# rename the column train into whole_dataset\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/null/code/PromptGPT/scrape_websiste.ipynb#W3sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m dataset \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39;49mrename_column(\u001b[39m\"\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mwhole_dataset\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/temoctalk/lib/python3.10/site-packages/datasets/dataset_dict.py:390\u001b[0m, in \u001b[0;36mDatasetDict.rename_column\u001b[0;34m(self, original_column_name, new_column_name)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    353\u001b[0m \u001b[39mRename a column in the dataset and move the features associated to the original column under the new column name.\u001b[39;00m\n\u001b[1;32m    354\u001b[0m \u001b[39mThe transformation is applied to all the datasets of the dataset dictionary.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[39m```\u001b[39;00m\n\u001b[1;32m    387\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    388\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_values_type()\n\u001b[1;32m    389\u001b[0m \u001b[39mreturn\u001b[39;00m DatasetDict(\n\u001b[0;32m--> 390\u001b[0m     {\n\u001b[1;32m    391\u001b[0m         k: dataset\u001b[39m.\u001b[39mrename_column(original_column_name\u001b[39m=\u001b[39moriginal_column_name, new_column_name\u001b[39m=\u001b[39mnew_column_name)\n\u001b[1;32m    392\u001b[0m         \u001b[39mfor\u001b[39;00m k, dataset \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems()\n\u001b[1;32m    393\u001b[0m     }\n\u001b[1;32m    394\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/temoctalk/lib/python3.10/site-packages/datasets/dataset_dict.py:391\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    353\u001b[0m \u001b[39mRename a column in the dataset and move the features associated to the original column under the new column name.\u001b[39;00m\n\u001b[1;32m    354\u001b[0m \u001b[39mThe transformation is applied to all the datasets of the dataset dictionary.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[39m```\u001b[39;00m\n\u001b[1;32m    387\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    388\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_values_type()\n\u001b[1;32m    389\u001b[0m \u001b[39mreturn\u001b[39;00m DatasetDict(\n\u001b[1;32m    390\u001b[0m     {\n\u001b[0;32m--> 391\u001b[0m         k: dataset\u001b[39m.\u001b[39;49mrename_column(original_column_name\u001b[39m=\u001b[39;49moriginal_column_name, new_column_name\u001b[39m=\u001b[39;49mnew_column_name)\n\u001b[1;32m    392\u001b[0m         \u001b[39mfor\u001b[39;00m k, dataset \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems()\n\u001b[1;32m    393\u001b[0m     }\n\u001b[1;32m    394\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/temoctalk/lib/python3.10/site-packages/datasets/arrow_dataset.py:578\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[39mself\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    577\u001b[0m \u001b[39m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 578\u001b[0m out: Union[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDatasetDict\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    579\u001b[0m datasets: List[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(out\u001b[39m.\u001b[39mvalues()) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(out, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m [out]\n\u001b[1;32m    580\u001b[0m \u001b[39mfor\u001b[39;00m dataset \u001b[39min\u001b[39;00m datasets:\n\u001b[1;32m    581\u001b[0m     \u001b[39m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/temoctalk/lib/python3.10/site-packages/datasets/fingerprint.py:511\u001b[0m, in \u001b[0;36mfingerprint_transform.<locals>._fingerprint.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    507\u001b[0m             validate_fingerprint(kwargs[fingerprint_name])\n\u001b[1;32m    509\u001b[0m \u001b[39m# Call actual function\u001b[39;00m\n\u001b[0;32m--> 511\u001b[0m out \u001b[39m=\u001b[39m func(dataset, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    513\u001b[0m \u001b[39m# Update fingerprint of in-place transforms + update in-place history of transforms\u001b[39;00m\n\u001b[1;32m    515\u001b[0m \u001b[39mif\u001b[39;00m inplace:  \u001b[39m# update after calling func so that the fingerprint doesn't change if the function fails\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/temoctalk/lib/python3.10/site-packages/datasets/arrow_dataset.py:2181\u001b[0m, in \u001b[0;36mDataset.rename_column\u001b[0;34m(self, original_column_name, new_column_name, new_fingerprint)\u001b[0m\n\u001b[1;32m   2179\u001b[0m dataset \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mdeepcopy(\u001b[39mself\u001b[39m)\n\u001b[1;32m   2180\u001b[0m \u001b[39mif\u001b[39;00m original_column_name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m dataset\u001b[39m.\u001b[39m_data\u001b[39m.\u001b[39mcolumn_names:\n\u001b[0;32m-> 2181\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   2182\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mOriginal column name \u001b[39m\u001b[39m{\u001b[39;00moriginal_column_name\u001b[39m}\u001b[39;00m\u001b[39m not in the dataset. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2183\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCurrent columns in the dataset: \u001b[39m\u001b[39m{\u001b[39;00mdataset\u001b[39m.\u001b[39m_data\u001b[39m.\u001b[39mcolumn_names\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2184\u001b[0m     )\n\u001b[1;32m   2185\u001b[0m \u001b[39mif\u001b[39;00m new_column_name \u001b[39min\u001b[39;00m dataset\u001b[39m.\u001b[39m_data\u001b[39m.\u001b[39mcolumn_names:\n\u001b[1;32m   2186\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   2187\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNew column name \u001b[39m\u001b[39m{\u001b[39;00mnew_column_name\u001b[39m}\u001b[39;00m\u001b[39m already in the dataset. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2188\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPlease choose a column name which is not already in the dataset. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2189\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCurrent columns in the dataset: \u001b[39m\u001b[39m{\u001b[39;00mdataset\u001b[39m.\u001b[39m_data\u001b[39m.\u001b[39mcolumn_names\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2190\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Original column name train not in the dataset. Current columns in the dataset: ['base_prompt', 'improved_prompt', 'views']"
     ]
    }
   ],
   "source": [
    "# convert a csv files into a datasets from the dataset libraries\n",
    "from datasets import load_dataset\n",
    "from rich import print\n",
    "\n",
    "dataset = load_dataset(\"csv\", data_files=\"prompt.csv\")\n",
    "\n",
    "# upload the dataset to the Hugging Face Hub Rami\n",
    "\n",
    "dataset.push_to_hub(\"Rami/prompts\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "temoctalk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
